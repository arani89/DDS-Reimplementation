{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup DDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clone GitHub [repository](https://github.com/rahisenpai/DDS.git) and update submodules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "f614ea93-ad0e-464d-bb7b-4a26bda62a03"
      },
      "outputs": [],
      "source": [
        "#clone DDS repo, if not present, to ensure correct directory structure\n",
        "# !git clone https://github.com/rahisenpai/DDS.git\n",
        "\n",
        "#ensure submodules are present\n",
        "!git submodule update --init --recursive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qr yolov5/requirements.txt #install dependencies for yolov5\n",
        "\n",
        "!apt install ffmpeg #install ffmpeg to process videos and frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMuzaVXxnmaO"
      },
      "source": [
        "# Set up runtime environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import required modules and check PyTorch and GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9BaJSyJnGPg",
        "outputId": "fe6d91cd-0ffd-48e3-b55d-ffade39f2d4a"
      },
      "outputs": [],
      "source": [
        "#change current working directory to the directory where yolov5 is cloned\n",
        "%cd yolov5\n",
        "\n",
        "#import required modules\n",
        "import torch\n",
        "import utils\n",
        "import os\n",
        "import subprocess\n",
        "from PIL import Image\n",
        "\n",
        "display = utils.notebook_init()  #checks\n",
        "#change current working directory back to the directory where DDS is cloned\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDLEUA4GmhJW"
      },
      "source": [
        "Set video name, min and max threshold confidence/inference values to filter objects in second pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGj2yyL_A5jQ"
      },
      "outputs": [],
      "source": [
        "video_name = 'MVI_40991' #don't add extension\n",
        "min_conf = '0.2'\n",
        "max_conf = '0.25'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLWg0GWVBBXr"
      },
      "source": [
        "# DDS First Pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First manipulation of video with ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9akx30f1nwLs"
      },
      "outputs": [],
      "source": [
        "#extract raw files from video\n",
        "!ffmpeg -i input/{video_name}.mp4 -pix_fmt yuv420p media/raw_files/{video_name}.y4m\n",
        "\n",
        "#change qp to 36 and resolution to 0.6\n",
        "!ffmpeg -i media/raw_files/{video_name}.y4m -c:v libx264 -qp 36 -r 30 -vf scale=iw*0.6:ih*0.6 media/first_pass_input/{video_name}.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSjpB4cQur3T"
      },
      "source": [
        "First YOLOv5 run on video  \n",
        "\n",
        "`--conf {min_conf}` sets confidence threshold to `min_conf` declared earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uyCTYdK5uuWb"
      },
      "outputs": [],
      "source": [
        "!python3 yolov5/detect.py --weights yolov5s.pt --conf {min_conf} --source media/first_pass_input/{video_name}.mp4 --save-txt --save-conf --project results --name {video_name}_first"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DDS Second Pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5GwVwNK6vIh"
      },
      "source": [
        "Find objects with confidence values between `min_conf` and `max_conf` from the results produced in first pass and store them in `results/{video_name}_first}/required_objects.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dbLbIJmN6uLm"
      },
      "outputs": [],
      "source": [
        "#all objects and their confidence values are stored in labels directory in results\n",
        "labels_path = 'results/'+video_name+'_first/labels'\n",
        "files = os.listdir(labels_path)\n",
        "# print('Number of labels in the video: ',len(files))\n",
        "\n",
        "start = len(video_name)+1\n",
        "\n",
        "def get_numeric_part(filename):\n",
        "  #extract the numeric part from the filename, format is '{video_name}_num.txt'\n",
        "  #num represents frame number\n",
        "  return int(filename[start:-4])\n",
        "\n",
        "#sort to process frames faster in next steps\n",
        "files.sort(key=get_numeric_part)\n",
        "\n",
        "#path to store required_objects.txt\n",
        "req_obj_path = 'results/'+video_name+'_first/required_objects.txt'\n",
        "\n",
        "with open(req_obj_path, 'w') as req_obj_file:\n",
        "  for label_name in files:\n",
        "    input_file_path = labels_path+'/'+label_name\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "      for line in input_file:\n",
        "        entry = line.split()\n",
        "        if float(entry[-1])>=float(min_conf) and float(entry[-1])<=float(max_conf):\n",
        "          req_obj_file.write(label_name[start:-4]+' '+line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create directories to store and process frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p media/raw_frames/{video_name}\n",
        "!mkdir -p media/frame_crops/{video_name}\n",
        "!mkdir -p media/processed_frames/{video_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYeSDGPddQ23"
      },
      "source": [
        "\n",
        "Second Manipulation of video with ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdEpAkRlndvR"
      },
      "outputs": [],
      "source": [
        "#extract all frames from raw_files extracted earlier\n",
        "!ffmpeg -i media/raw_files/{video_name}.y4m -r 30 media/raw_frames/{video_name}/%d.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Darken portions not needed in second pass in every frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-VBtLtDrjgD"
      },
      "outputs": [],
      "source": [
        "def normalized_to_absolute(x, y, w, h, img_width, img_height):\n",
        "  #returns coordinates to crop the object\n",
        "  left = int(x * img_width)\n",
        "  top = int(y * img_height)\n",
        "  right = int((x + w) * img_width)\n",
        "  bottom = int((y + h) * img_height)\n",
        "  return (left, top, right, bottom)\n",
        "\n",
        "def create_black_background(width, height, save_path):\n",
        "  #creates a black background to paste the crops of objects (if any)\n",
        "  subprocess.run([\n",
        "    'ffmpeg', '-f', 'lavfi', f'-i', f'color=c=black:s={width}x{height}', '-frames:v', '1', save_path\n",
        "  ])\n",
        "\n",
        "def crop_image(image_path, coordinates, cropped_image_path):\n",
        "  #open the original image\n",
        "  image = Image.open(image_path)\n",
        "  img_width, img_height = image.size\n",
        "  #convert normalized coordinates to absolute pixel coordinates\n",
        "  abs_coords = normalized_to_absolute(*coordinates, img_width, img_height)\n",
        "  #crop the image\n",
        "  cropped_image = image.crop(abs_coords)\n",
        "  #save the cropped image\n",
        "  cropped_image.save(cropped_image_path)\n",
        "  #return the top-left coordinates of the cropped image\n",
        "  return (abs_coords[0], abs_coords[1])\n",
        "\n",
        "def overlay_cropped_on_black(original_image_path, cropped_image_path, output_image_path, coordinates):\n",
        "  #crop the image and get the top-left coordinates of the cropped area\n",
        "  top_left = crop_image(original_image_path, coordinates, cropped_image_path)\n",
        "  #overlay the cropped portion\n",
        "  subprocess.run([\n",
        "      'ffmpeg', '-i', output_image_path, '-i', cropped_image_path, '-filter_complex', f'overlay={top_left[0]}:{top_left[1]}', 'temp.png'\n",
        "  ])\n",
        "  subprocess.run(['mv', 'temp.png', output_image_path])\n",
        "\n",
        "\n",
        "req_obj_path = 'results/'+video_name+'_first/required_objects.txt'\n",
        "raw_frames_path = f'media/raw_frames/{video_name}'\n",
        "frame_crops_path = f'media/frame_crops/{video_name}'\n",
        "processed_frames_path = f'media/processed_frames/{video_name}'\n",
        "\n",
        "with Image.open('media/raw_frames'+f'/{video_name}/1.png') as img:\n",
        "  frame_width, frame_height = img.size\n",
        "# print(width, height)\n",
        "\n",
        "frame_num, crop_cnt = 1, 1\n",
        "with open(req_obj_path, 'r') as req_obj_file:\n",
        "  for line in req_obj_file:\n",
        "    temp_entry = line.split()\n",
        "    entry = [float(x) for x in temp_entry]\n",
        "\n",
        "    #adding black frames for frames which don't have any required object\n",
        "    while(int(entry[0])>=frame_num):\n",
        "      create_black_background(frame_width, frame_height, f'{processed_frames_path}/{frame_num}.png')\n",
        "      frame_num += 1\n",
        "\n",
        "    #processing required frame now\n",
        "    frame_num -= 1\n",
        "    coordinates = entry[2:-1]\n",
        "    coordinates[0] -= coordinates[2]/2\n",
        "    coordinates[1] -= coordinates[3]/2\n",
        "    overlay_cropped_on_black(f'{raw_frames_path}/{frame_num}.png',\n",
        "      f'{frame_crops_path}/{crop_cnt}.png', f'{processed_frames_path}/{frame_num}.png', coordinates)\n",
        "    crop_cnt += 1\n",
        "    frame_num += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compile all processed_frames into a video with qp 30 and resolution 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_i5ATrZpxfqr"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -framerate 30 -i media/processed_frames/{video_name}/%d.png -c:v libx264 -qp 30 -vf \"scale=iw*0.8:ih*0.8\" -pix_fmt yuv420p media/second_pass_input/{video_name}.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2oGwVU0RN20"
      },
      "source": [
        "Second YOLOv5 run on video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4IfdvKcRRrl"
      },
      "outputs": [],
      "source": [
        "!python3 yolov5/detect.py --weights yolov5s.pt --conf {min_conf} --source media/second_pass_input/{video_name}.mp4 --save-txt --save-conf --project results --name {video_name}_second"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#clear all videos and images generated to produce results\n",
        "!rm -rf media/raw_files/{video_name}.y4m\n",
        "!rm -rf media/first_pass_input/{video_name}.mp4\n",
        "!rm -rf media/raw_frames/{video_name}\n",
        "!rm -rf media/frame_crops/{video_name}\n",
        "!rm -rf media/processed_frames/{video_name}\n",
        "!rm -rf media/second_pass_input/{video_name}.mp4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
